%%%%%%%%%%%%%%%%%%%%%%%% referenc.tex %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% sample references
% %
% Use this file as a template for your own input.
%
%%%%%%%%%%%%%%%%%%%%%%%% Springer-Verlag %%%%%%%%%%%%%%%%%%%%%%%%%%
%
% BibTeX users please use
% \bibliographystyle{}
% \bibliography{}
%
%\biblstarthook{In view of the parallel print and (chapter-wise) online publication of your book at \url{www.springerlink.com} it has been decided that -- as a genreral rule --  references should be sorted chapter-wise and placed at the end of the individual chapters. However, upon agreement with your contact at Springer you may list your references in a single seperate chapter at the end of your book. Deactivate the class option \texttt{sectrefs} and the \texttt{thebibliography} environment will be put out as a chapter of its own.\\\indent
%References may be \textit{cited} in the text either by number (preferred) or by author/year.\footnote{Make sure that all references from the list are cited in the text. Those not cited should be moved to a separate \textit{Further Reading} section or chapter.} The reference list should ideally be \textit{sorted} in alphabetical order -- even if reference numbers are used for the their citation in the text. If there are several works by the same author, the following order should be used:
%\begin{enumerate}
%\item all works by the author alone, ordered chronologically by year of publication
%\item all works by the author with a coauthor, ordered alphabetically by coauthor
%\item all works by the author with several coauthors, ordered chronologically by year of publication.
%\end{enumerate}
%The \textit{styling} of references\footnote{Always use the standard abbreviation of a journal's name according to the ISSN \textit{List of Title Word Abbreviations}, see \url{http://www.issn.org/en/node/344}} depends on the subject of your book:
%\begin{itemize}
%\item The \textit{two} recommended styles for references in books on \textit{mathematical, physical, statistical and computer sciences} are depicted in ~\cite{science-contrib, science-online, science-mono, science-journal, science-DOI} and ~\cite{phys-online, phys-mono, phys-journal, phys-DOI, phys-contrib}.
%\item Examples of the most commonly used reference style in books on \textit{Psychology, Social Sciences} are~\cite{psysoc-mono, psysoc-online,psysoc-journal, psysoc-contrib, psysoc-DOI}.
%\item Examples for references in books on \textit{Humanities, Linguistics, Philosophy} are~\cite{humlinphil-journal, humlinphil-contrib, humlinphil-mono, humlinphil-online, humlinphil-DOI}.
%\item Examples of the basic Springer style used in publications on a wide range of subjects such as \textit{Computer Science, Economics, Engineering, Geosciences, Life Sciences, Medicine, Biomedicine} are ~\cite{basic-contrib, basic-online, basic-journal, basic-DOI, basic-mono}.
%\end{itemize}
%}

\begin{thebibliography}{99.}%
% and use \bibitem to create references.
%
% Use the following syntax and markup for your references if
% the subject of your book is from the field
% "Mathematics, Physics, Statistics, Computer Science"
%
% Contribution
%\bibitem{science-contrib} Broy, M.: Software engineering --- from auxiliary to key technologies. In: Broy, M., Dener, E. (eds.) Software Pioneers, pp. 10-13. Springer, Heidelberg (2002)
%%
%% Online Document
%\bibitem{science-online} Dod, J.: Effective substances. In: The Dictionary of Substances and Their Effects. Royal Society of Chemistry (1999) Available via DIALOG. \\
%\url{http://www.rsc.org/dose/title of subordinate document. Cited 15 Jan 1999}
%%
%% Monograph
%\bibitem{science-mono} Geddes, K.O., Czapor, S.R., Labahn, G.: Algorithms for Computer Algebra. Kluwer, Boston (1992)
%%
%% Journal article
%\bibitem{science-journal} Hamburger, C.: Quasimonotonicity, regularity and duality for nonlinear systems of partial differential equations. Ann. Mat. Pura. Appl. \textbf{169}, 321--354 (1995)
%%
%% Journal article by DOI
%\bibitem{science-DOI} Slifka, M.K., Whitton, J.L.: Clinical implications of dysregulated cytokine production. J. Mol. Med. (2000) doi: 10.1007/s001090000086
\bibitem{comparison} S. Davis,Signal Technology, Inc.,Santa Barbara, CA,P. Mermelstein, Comparison of parametric representations for monosyllabic word recognition in continuously spoken sentences, IEEE Transactions on Acoustics, Speech, and Signal Processing, pp.357-366,1980.
\bibitem{maximum} R. Gopinath, Maximum likelihood modeling with Gaussian distributions for classification, Proc. IEEE ICASSP,pp.661-664,1980.
\bibitem{text}  Sojka, P., Hor¨¢k, A., Kope?ek, I., Pala, K, Text, Speech and Dialogue, 17th International Conference on Text, Speech and Dialogue,2014.
\bibitem{semitied} M. J. F. Gales, Semi-tied covariance matrices for hidden Markov models, IEEE Transactions on Speech and Audio Processing,pp.272-281,vol.7,1999.
\bibitem{implement} S Umesh, A Zolnay, H Ney, Implementing Frequency-Warping and VTLN Through Linear Transformation of Conventional MFCC, Interspeech,pp.269-272,2005.
\bibitem{vtln} E Variani, T Schaaf,  VTLN in the MFCC Domain: Band-Limited versus Local Interpolation, IEEE Transactions on Audio, Speech, and Language Processing,pp.1573 - 1584,vol.20,2012.
\bibitem{frequency} L. Lee,R. Rose, A frequency warping approach to speaker normalization,IEEE Transactions on Speech and Audio Processing,pp.49-60,vol.6,1998.
\bibitem{vocal} Zhan, Puming, Waibel, Alex, Vocal Tract Length Normalization for Large Vocabulary Continuous Speech Recognition,1997. \\
\url{http://www.dtic.mil/get-tr-doc/pdf?AD=ADA333514}
\bibitem{using} D. Y. Kim, S. Umesh, M. J. F. Gales, T. Hain and P. C. Woodland, Using VTLN for broadcast news transcription, Acoustics, Speech, and Signal Processing,2004.
\bibitem{tract} L. Saheer; J. Dines; P. N. Garner, Vocal Tract Length Normalization for Statistical Parametric Speech Synthesis, IEEE Transactions on Audio, Speech, and Language Processing,pp.2134-2148,vol.20,2012.
\bibitem{note} Daniel Povey, NOTES FOR AFFINE TRANSFORM-BASED VTLN,2010. \\
\url{http://www.danielpovey.com/files/2010\_vtln\_notes.pdf}
\bibitem{tutorial} Jonathon Shlens, A Tutorial on Principal Component Analysis,2014. \\
\url{http://arxiv.org/pdf/1404.1100v1.pdf}
\bibitem{least} L. P. Liu; Y. Jiang; Z. H. Zhou,Least Square Incremental Linear Discriminant Analysis,Ninth IEEE International Conference on Data Mining,pp.298-306,2009.
\bibitem{linear} S. Balakrishnama, A. Ganapathiraju, LINEAR DISCRIMINANT ANALYSIS - A BRIEF TUTORIAL. \\
\url{https://www.isip.piconepress.com/publications/reports/1998/isip/lda/lda\_theory.pdf}
\bibitem{analysis} J Ye, R Janardan, Q Li,  Two-dimensional linear discriminant analysis,Neural Information Processing Systems,pp.13-18,2004.
\bibitem{denoise} Xue Feng, Yaodong Zhang,J. Glass, Speech feature denoising and dereverberation via deep autoencoders for noisy reverberant speech recognition,Acoustics, Speech and Signal Processing (ICASSP), 2014 IEEE International Conference on,pp.1759-1763,2014.
\bibitem{stack} Pascal Vincent,Hugo Larochelle,Isabelle Lajoie,Yoshua Bengio,Pierre-Antoine Manzagol, Stacked Denoising Autoencoders: Learning Useful Representations in
a Deep Network with a Local Denoising Criterion, Journal of Machine Learning Research,pp.3371-3408,vol.11,2010.
\end{thebibliography}
